{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "714dd752",
   "metadata": {},
   "source": [
    "# 5.4 Least-Squares Problems\n",
    "\n",
    "Linear systems arising in applications are often inconsistent. In such situations, the best one can do is to find a vector $\\vec{x}'$ that makes $A\\vec{x}$ as close as possible to $\\vec{b}$. We think of $A\\vec{x}$ as an approximation of $\\vec{b}$. The smaller $\\|\\vec{b} - A\\vec{x}\\|$, the better the approximation. Therefore, we are looking for a vector $\\hat{y}$ such that $\\|\\vec{b} - A\\hat{x}\\|$ is as small as possible. Such $\\vec{y}$ is called the _least square solution_ of $A\\vec{x} = \\vec{b}$. The name is motivated by the fact that $\\|\\vec{b} - A\\hat{x}\\|$ is the square root of a sum of squares. In this section we explore this idea further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83b7be",
   "metadata": {},
   "source": [
    "Let $A\\vec{x} = \\vec{b}$ be inconsistent, which implies $\\vec{b}\\notin \\text{col}(A)$. Note that no matter what $\\vec{x}$ is, $A\\vec{x}$ lies in $\\text{col}(A)$. From Section 5.2, we know that the closest point to $\\vec{b}$ in $\\text{col}(A)$ is the projection of $\\vec{b}$ onto $\\text{col}(A)$ (the best approximation problem). Let $\\hat{b} = \\text{proj}_{\\text{col}(A)}(\\vec{b})$. Since $A\\vec{x} = \\hat{b}$ is consistent, there are $\\hat{x}$ such that $A\\hat{x} = \\hat{b}$. $\\hat{x}$ is a least square solution of $A\\vec{x} = \\vec{b}$. Recall that $\\vec{b} -\\hat{b}$ is orthogonal to $\\text{col}(A)$, and thus so is $\\vec{b} - A\\hat{x}$. In other words, $\\vec{b} - A\\hat{x}$ is orthogonal to each column of $A$, and we have:\n",
    "\n",
    "$$\n",
    "A^{T}(\\vec{b} - A\\hat{x}) = 0 \\quad \\text{or} \\quad A^{T}A\\vec{x}= A^{T}\\vec{b}.\n",
    "$$\n",
    "\n",
    "The equation $A^{T}A\\vec{x}= A^{T}\\vec{b}$ is called the __normal equation__ for $A\\vec{x} = \\vec{b}$.\n",
    "\n",
    "__Theorem 1__\n",
    "\n",
    "The set of least-squares solutions of $A\\vec{x} = \\vec{b}$ coincides with the nonempty set of solutions of the normal equation $A^{T}A\\vec{x}= A^{T}\\vec{b}$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__Example 1__\n",
    "\n",
    "Find a least-squares solution of the inconsistent system $A\\vec{x} = \\vec{b}$ for $A = \\begin{bmatrix} 4 & 2\\\\ 0 & 2 \\\\ 1 & 1 \\end{bmatrix}$ and $\\vec{b} = \\begin{bmatrix} 2 \\\\0 \\\\11 \\end{bmatrix}$.\n",
    "\n",
    "__Solution:__ (1) Find $A^TA$ and $A^T\\vec{b}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39e0cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you code\n",
    "import numpy as np\n",
    "\n",
    "#A = \n",
    "\n",
    "#b = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a9860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute A^TA\n",
    "#ATA = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db94f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute A^Tb\n",
    "#ATb = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb33e0b",
   "metadata": {},
   "source": [
    "(2) Write down the normal equation:\n",
    "\n",
    "To solve this equation, we can use row operations; alternatively, if $A^TA$ is invertible, we can use the invertible matrix theorem. In many calculations, $A^TA$ is invertible, but this is not always the case. In Theorem 2, we will see when this is true. \n",
    "\n",
    "(3) Write down the least square solution $\\hat{x}$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee29e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing x_hat\n",
    "\n",
    "#x_hat ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dfe9ed",
   "metadata": {},
   "source": [
    "\n",
    "__Example 2__ Find a least-squares solution of the inconsistent system $A\\vec{x} = \\vec{b}$ for $A = \\begin{bmatrix} 1 & 1 & 0 & 0\\\\ 1 & 1 & 0 & 0\\\\ 1 & 0 & 1 & 0\\\\1 & 0 & 1 & 0 \\\\1 & 0 & 0 & 1\\\\1 & 0 & 0 & 1 \\end{bmatrix}$ and $\\vec{b} = \\begin{bmatrix} -3 \\\\-1 \\\\0 \\\\2 \\\\5 \\\\1 \\end{bmatrix}$. \n",
    "\n",
    "Set up the normal equation for $A\\vec{x} = \\vec{b}$, and find a solution for it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4da949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a3d56",
   "metadata": {},
   "source": [
    "Your normal equation should be\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 6 & 2 & 2 & 2 \\\\ 2 & 2 & 0 & 0 \\\\ 2 & 0 & 2 & 0 \\\\ 2 & 0 & 0 & 2 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} = \\begin{bmatrix} 4 \\\\ -4 \\\\ 2 \\\\6 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "To solve this equation, form its augmented matrix and use the row operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e46a9838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aumented matrix: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2add49",
   "metadata": {},
   "source": [
    "Call row operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad6d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap two rows\n",
    "\n",
    "def swap(matrix, row1, row2):\n",
    "    \n",
    "    copy_matrix=np.copy(matrix).astype('float64') \n",
    "  \n",
    "    copy_matrix[row1,:] = matrix[row2,:]\n",
    "    copy_matrix[row2,:] = matrix[row1,:]\n",
    "    \n",
    "    return copy_matrix\n",
    "\n",
    "\n",
    "# Multiple all entries in a row by a nonzero number\n",
    "\n",
    "\n",
    "def scale(matrix, row, scalar):\n",
    "    copy_matrix=np.copy(matrix).astype('float64') \n",
    "    copy_matrix[row,:] = scalar*matrix[row,:]  \n",
    "    return copy_matrix\n",
    "\n",
    "# Replacing a row1 by the sum of itself and a multiple of rpw2 \n",
    "\n",
    "def replace(matrix, row1, row2, scalar):\n",
    "    copy_matrix=np.copy(matrix).astype('float64')\n",
    "    copy_matrix[row1] = matrix[row1]+ scalar * matrix[row2] \n",
    "    return copy_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf465b5",
   "metadata": {},
   "source": [
    "From the REF of the augmented matrix, we can see that the general least-squares solution of $A\\vec{x} = \\vec{b}$ has the form:\n",
    "\n",
    "$$\n",
    "\\hat{x} = \\begin{bmatrix} 3 \\\\ -5 \\\\ -2 \\\\ 0 \\end{bmatrix} + x_4 \\begin{bmatrix} -1 \\\\ 1 \\\\ 1 \\\\ 0 \\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597b9c76",
   "metadata": {},
   "source": [
    "Any linear system $A\\vec{x} = \\vec{b}$ admits at least one least-squares solution (the orthogonal projection $\\hat{b}$). For example, the least-squares solution of $A\\vec{x} = \\vec{b}$ in Example 1 was unique, while the linear system in Example 2 has infinitely many least-squares solutions.\n",
    "\n",
    "The next theorem gives useful criteria for determining when there is only one least-squares solution.\n",
    "\n",
    "__Theorem 2__ \n",
    "\n",
    "Let $A$ be an $m\\times n$ matrix. The following statements are equivalent:\n",
    "\n",
    "   1. The equation $A\\vec{x} = \\vec{b}$ has a unique least-squares solution for each $\\vec{b}\\in \\mathbb{R}^n$.\n",
    "   \n",
    "   2. The columns of $A$ are linearly independent.\n",
    "   \n",
    "   3. The matrix $A^TA$ is invertible.\n",
    "   \n",
    "In any of these cases, the least-squares solution $\\hat{x}$ is given by:\n",
    "\n",
    "$$\n",
    "\\hat{x} = (A^TA)^{-1} A^T \\vec{b}.\n",
    "$$\n",
    "\n",
    "Moreover, if $A = QR$ is a $QR$-factorization of $A$, then the least-squares solution $\\hat{x}$ is given by:\n",
    "\n",
    "$$\n",
    "\\hat{x} = R^{-1} Q^{T} \\vec{b}. \\quad (*)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8a6ac8",
   "metadata": {},
   "source": [
    "__Example 3:__\n",
    "\n",
    "Let $A = \\begin{bmatrix} 1 & 3 & 5 \\\\ 1 & 1 & 0 \\\\ 1 & 1 & 2 \\\\ 1 & 3 & 3\\end{bmatrix}$ and $\\vec{b} = \\begin{bmatrix} 3 \\\\ 5 \\\\ 7 \\\\ -3 \\end{bmatrix}$. Find a least-squares solution of $A\\vec{x} = \\vec{b}$ using the QR-factorization of $A$.\n",
    "\n",
    "__Solution:__\n",
    "\n",
    "Hint: A QR-factorization of $A$ can be obtained as in Section 5.3 using `numpy.linalg.qr()`. Your answer shoudl be: $\\hat{x} = \\begin{bmatrix} 10\\\\ -6\\\\ 2 \\end{bmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd28d338",
   "metadata": {},
   "source": [
    "## Numerical Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d4d8e0",
   "metadata": {},
   "source": [
    "Since $R$ in $(*)$ is an upper triangular matrix, we can alternatively compute $\\hat{x}$ by finding the exact solutions of:\n",
    "\n",
    "$$\n",
    "R\\hat{x} = Q^{T} \\vec{b}. \\quad (**)\n",
    "$$\n",
    "\n",
    "For large matrices, solving $(**)$ by back-substitution or row operations is faster than computing $R^{-1}$ and using $(*)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd963ef",
   "metadata": {},
   "source": [
    "## Excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05dfbe",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Let $A = \\begin{bmatrix} 1 & -3 & -3 \\\\  1 & 5 & 1 \\\\ 1 & 1 & 2 \\\\ 1 & 7 & 2\\end{bmatrix}$ and $\\vec{b} = \\begin{bmatrix} 5 \\\\ -3 \\\\ -5 \\end{bmatrix}$.\n",
    "\n",
    "    a.  Find a least-squares solution of $A\\vec{x} = \\vec{b}$.\n",
    "    \n",
    "    b. Compute the associated least-squares error $\\| \\vec{b} - A\\hat{x}\\|$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. Describe all least-squares solutions of the system\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    x + y &= 2 \\\\ \n",
    "    x + y &= 4 \\\\ \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8cddf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
