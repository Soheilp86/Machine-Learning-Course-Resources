{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d3bb7c7",
   "metadata": {},
   "source": [
    "# Consumer-Product Matrix\n",
    "\n",
    "A Consumer-product matrix is an $m \\times n$ matrix $C$, where each row represents a consumer, and each column corresponds to a product. The element $c_{ij}$ in this matrix represents the probability that consumer $i$ will buy or like product $j$. \n",
    "\n",
    "To put it simply, our goal is to gain insights into the factors influencing people's purchasing decisions. We want to use this understanding to predict their future choices, even when we lack complete information.\n",
    "\n",
    "We are assuming that certain hidden characteristics, such as age, gender, income, etc., impact consumers' buying decisions, and the decision of each consumer is only a function of these hidden features. \n",
    "\n",
    "With this hypothesis we can rewrite $C = AB$. The matrix $A$ reflects the extent to which hidden features influence each consumer's choices, and the matrix $B$ provides information about the probability of a consumer buying or liking a product based on a specific hidden feature.\n",
    "\n",
    "In an ideal scenario, we'd have complete data in our large table. However, in reality, data gaps are common, and our goal is to predict missing information. This is where challenges like the Netflix challenge come into play, where we are given some ratings and tasked with predicting ratings for other movies. In online advertising, we aim to determine which ad is best for a user based on their past purchases.\n",
    "\n",
    "In this lab, we usebest k rank for Movie Recommendations (for more information, please refer to the related videos posted on Moodle for this week).\n",
    "\n",
    "Instructions:\n",
    "\n",
    "**Step 1:** Data Gathering \n",
    "\n",
    "**Step 2:** Data Preprocesing\n",
    "\n",
    "**Step 3:** The best k rank predicts ratings!!!\n",
    "\n",
    "**Step 4:** Writing a function to recommend movies for any user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fb3f98",
   "metadata": {},
   "source": [
    "**Step 1: Data Gathering:**\n",
    "\n",
    "1. Start by importing the necessary Python libraries, such as Numpy and Pandas.\n",
    "2. Next, visit the provided URL: http://grouplens.org/datasets/movielens/. Under the \"recommended for education and development\" section, locate and download the file named `ml-latest-small.zip` (which has a size of 1 MB).\n",
    "3. After downloading, import the CSV files contained within the zip file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65131658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccd06673",
   "metadata": {},
   "source": [
    "**Step 2: Data Preprocessing:**\n",
    "\n",
    "1. Begin by examining the first few rows of your data to familiarize yourself with its structure.\n",
    "2. Transform the data so that each row represents a user. You can achieve this using the `.pivot()` function.\n",
    "3. Note that 'NaN' values in the dataset represent missing or unrated movies by users. Common treatment to handle these 'NaN' values include replacing them with zero or the average rating for each row or column. Discuss which one do you think is better. Use `.fillna()`\n",
    "4. Convert this transformed table into a numerical matrix (C). \n",
    "5. Discuss whether feature normalization is necessary for this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6248a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71f35a",
   "metadata": {},
   "source": [
    "**Step 3: Finding the Best Rank k:**\n",
    "\n",
    "The best rank $k$ is a matrix with prediction values; discuss this. \n",
    "\n",
    "1. Use k = 50. Determining the optimal rank 'k' for movie recomendation is another problem which can be the topic of your final project.\n",
    "\n",
    "2. Computing SVD might be time consuming. If thats the case, discuss how to find an effcient algorithim.\n",
    "\n",
    "3. From this matrix, construct the corresponding dataframe using: pd.DataFrame(prediction matrix, columns = original_dataframe.columns). This dataFrame will contain predicted ratings for movies by different users. Each row represents a user, and each column represents a movie, with the cells containing predicted ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05fb70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231d848",
   "metadata": {},
   "source": [
    "**Step 4: Movie Recommendations:**\n",
    "1. Pick a user retrieve its row in predictions and sort this in descending order (top-rated movies come first)\n",
    "\n",
    "2. For the same user, retrieve it's original ratings and merge this information with the movies data frame to gather details about the movies the user has already rated. Store this combined information user_full.\n",
    "\n",
    "3. Generate movie recommendations by merging the sorted predicted ratings with movie details and sorting the result by predicted ratings in descending order. The top-rated movies that the user hasn't seen yet are selected, and the specified number of recommendations is returned.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade124bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b04f9da",
   "metadata": {},
   "source": [
    "__Step 5__ Can you write a Python code that computes this for an arbitary user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34246c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1864122",
   "metadata": {},
   "source": [
    "Well Done! You are done with this lab too!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d126f1e7",
   "metadata": {},
   "source": [
    "__Note on Normalization:__\n",
    "    Normalization is a statistical method used in various fields, including statistics, data analysis, and machine learning, to scale or transform data in a way that allows for meaningful comparisons and analysis. The specific techniques and purposes of normalization can vary, but the general goal is to standardize or rescale data to a common range or distribution.\n",
    "\n",
    "In machine learning, it's common to normalize features to ensure that they have similar scales. This can improve the performance of many machine learning algorithms, such as gradient descent, which may converge faster and more reliably with normalized data.\n",
    "\n",
    "\n",
    "Common methods of normalization include:\n",
    "\n",
    "- **Min-Max Scaling:** This method scales the data to a specific range, often between 0 and 1. The formula for Min-Max scaling is `(x - min(x)) / (max(x) - min(x))`.\n",
    "\n",
    "- **Z-Score Standardization:** This method standardizes the data to have a mean of 0 and a standard deviation of 1. It's also called standardization or mean normalization. The formula for Z-Score standardization is `(x - mean(x)) / std(x)`.\n",
    "\n",
    "- **Log Transformation:** Taking the logarithm of data can be a form of normalization, especially when dealing with skewed or exponentially distributed data.\n",
    "\n",
    "- **Box-Cox Transformation:** This is a family of power transformations that can stabilize variance and make data closer to a normal distribution.\n",
    "\n",
    "- **Robust Scaling:** This method scales data using the median and interquartile range to handle outliers better.\n",
    "\n",
    "The choice of normalization method depends on the specific context and data distribution. Normalization can be a crucial step in data preprocessing to ensure that data is suitable for analysis or machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b9481",
   "metadata": {},
   "source": [
    "Refrences:\n",
    "\n",
    "1. https://web.stanford.edu/class/cs168/l/l9.pdf\n",
    "\n",
    "2. https://courses.cs.washington.edu/courses/cse521/16sp/521-lecture-9.pdf\n",
    "\n",
    "3. https://beckernick.github.io/datascience/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a5f458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
