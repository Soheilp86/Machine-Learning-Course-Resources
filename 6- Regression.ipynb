{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a0ab8fa",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "A common task in science and engineering is to underestand relationships between quantities that vary. The simplest relation between two variables $x$ and $y$ is the linear equation $y = mx + h$. Experimental data often produce points $(x_1, y_1), (x_2, y_2), \\dots (x_n, y_n)$ that, when graphed, seem to lie close to a line. We want to determine the parameters $m$ and $h$ that make the line as “close” to the points as possible. The coefficients $m$ and $h$  of the line are called (linear) regression coefficients. If the data points $(x_i, y_i) $were on the line, regression coefficients would satisfy the equations\n",
    "\n",
    "\\begin{align}\n",
    "    mx_1 + h &= y_1 \\\\\n",
    "    mx_2 + h &= y_2 \\\\\n",
    "    &\\vdots\\\\\n",
    "    mx_n + h &= y_n \\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Which can be written as \n",
    "\n",
    "$$\n",
    "A\\vec{x} = \\vec{b} \\quad \\text{where} \\quad A = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{bmatrix}, \\quad \\vec{x} = \\begin{bmatrix} h \\\\ m \\end{bmatrix} \\quad \\text{and} \\quad \\vec{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n  \\end{bmatrix}. \n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Of course, if the data points are not on a line (which often happens in practice), then $A\\vec{x} = \\vec{b}$ doesnt have a solution. Then we aim to find ordinary least-squares (OLS) solutions of $A\\vec{x} = \\vec{b}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176aa81b",
   "metadata": {},
   "source": [
    "## OLS Linear Regression Optimization Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daccdb1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Find $(h,m)$ which minimizes the loss function $J(h,m)$ defined as\n",
    "\n",
    "$$\n",
    "J(h,m)=\\tfrac{1}{2}\\sum_{i=1}^n (y_i-(h+mx_i) )^2=\\tfrac{1}{2}\\|\\vec{y} - \\vec{A}\\vec{x}\\|^2.\n",
    "$$\n",
    "\n",
    "(The factor of 1/2 multiplying the sum is introduced to simplify theoretical analysis of the loss function.)\n",
    "\n",
    "The loss function $J$ is  zero when the points are collinear and situated on the line $y= h + mx$; otherwise,  $J$  is positive, since it is  half the sum of the squared vertical separations between data points and the line  $y= h + mx$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359e6717",
   "metadata": {},
   "source": [
    "__Example 1__\n",
    "\n",
    "Find the equation $ y = mx +h$ that best fits the data points $(2, 1)\\, \\, (5, 2)\\,\\, (7, 3)\\,\\, \\text{and}\\, \\, (8, 3)$.\n",
    "\n",
    "__Solution:__\n",
    "\n",
    "1. Write down the matrix equation explianed above.\n",
    "\n",
    "2. Find the normal equation.\n",
    "\n",
    "3. Find the OLS solution using the previous lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985af41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6da225",
   "metadata": {},
   "source": [
    "we can also use `sklearn`'s `LinearRegression` model object. \n",
    "\n",
    "Here is the documentation for `LinearRegression`, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html</a>. \n",
    "\n",
    "\n",
    "__Example 2__  \n",
    "\n",
    "a. Generate data points distributed around the line $y = 4x - 3$ and plot them (__ChatGPT__).\n",
    "\n",
    "b. Clearly, the points in this dataset exhibit some collinearity. Find the regression line that best models the data.\n",
    "\n",
    "\n",
    "c. Plot the data points along with the regression line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80f19881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbec63d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dd6c6a1",
   "metadata": {},
   "source": [
    "## Excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9441b61d",
   "metadata": {},
   "source": [
    "1) Consider the data $(1, 0)$, $(4, 5)$, $(7, 8)$.  Use the normal equations  to find the least-squares solution line $y  = a + bx$ that best fits the data. \n",
    "\n",
    "\n",
    "2) Consider the data $(-1,1)$, $(0,0)$, $(1,2)$, $(2,3)$.  Use the normal equations to find the least-squares solution for the parabola $y=a+bx+cx^2$ that best fits the data.\n",
    "\n",
    "3) (ChatGPT) \n",
    "\n",
    "   a. Make up some data point that are around the line $y = x^2 +1$, and Plot them.\n",
    "    \n",
    "   b. Use the normal equations to find the least-squares solution for the parabola $y=a+bx+cx^2$ that best fits the data.\n",
    "    \n",
    "   c. Plot points along with regressor line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9fbeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c0943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
